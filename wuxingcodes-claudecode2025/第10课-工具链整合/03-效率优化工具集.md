# æ•ˆç‡ä¼˜åŒ–å·¥å…·é›†

> **ç”¨é€”**ï¼šClaudeCodeæ•ˆç‡ä¼˜åŒ–çš„å®ç”¨å·¥å…·å’Œè„šæœ¬é›†åˆ
> **ç‰ˆæœ¬**ï¼š2025å¹´12æœˆ
> **ä½œè€…**ï¼šå¤§ç†ŠæŒé—¨

## ğŸ“‹ ç›®å½•
1. [æ•ˆç‡åˆ†æå·¥å…·](#1-æ•ˆç‡åˆ†æå·¥å…·)
2. [è‡ªåŠ¨åŒ–è„šæœ¬](#2-è‡ªåŠ¨åŒ–è„šæœ¬)
3. [æ€§èƒ½ç›‘æ§å·¥å…·](#3-æ€§èƒ½ç›‘æ§å·¥å…·)
4. [ä¼˜åŒ–ç­–ç•¥åº“](#4-ä¼˜åŒ–ç­–ç•¥åº“)
5. [å®ç”¨å¿«æ·æ“ä½œ](#5-å®ç”¨å¿«æ·æ“ä½œ)

---

## 1. æ•ˆç‡åˆ†æå·¥å…·

### 1.1 å·¥ä½œæµæ•ˆç‡åˆ†æå™¨

```python
# workflow_analyzer.py
import json
import time
from datetime import datetime
from collections import defaultdict

class WorkflowEfficiencyAnalyzer:
    def __init__(self):
        self.metrics = defaultdict(list)
        self.start_times = {}

    def start_task(self, task_name, agent_name):
        """è®°å½•ä»»åŠ¡å¼€å§‹"""
        self.start_times[f"{task_name}_{agent_name}"] = {
            'start': time.time(),
            'timestamp': datetime.now()
        }

    def end_task(self, task_name, agent_name, success=True, notes=""):
        """è®°å½•ä»»åŠ¡ç»“æŸ"""
        key = f"{task_name}_{agent_name}"
        if key in self.start_times:
            duration = time.time() - self.start_times[key]['start']

            self.metrics[key].append({
                'duration': duration,
                'success': success,
                'notes': notes,
                'timestamp': self.start_times[key]['timestamp']
            })

            del self.start_times[key]

    def analyze_efficiency(self):
        """åˆ†ææ•ˆç‡æŒ‡æ ‡"""
        analysis = {
            'total_tasks': sum(len(tasks) for tasks in self.metrics.values()),
            'avg_duration': {},
            'success_rate': {},
            'bottlenecks': [],
            'optimization_suggestions': []
        }

        # è®¡ç®—æ¯ä¸ªä»»åŠ¡çš„å¹³å‡æ—¶é•¿å’ŒæˆåŠŸç‡
        for task_key, task_data in self.metrics.items():
            if task_data:
                durations = [t['duration'] for t in task_data]
                successes = [t for t in task_data if t['success']]

                task_name, agent_name = task_key.rsplit('_', 1)
                analysis['avg_duration'][task_key] = sum(durations) / len(durations)
                analysis['success_rate'][task_key] = len(successes) / len(task_data)

        # è¯†åˆ«ç“¶é¢ˆ
        bottlenecks = sorted(
            analysis['avg_duration'].items(),
            key=lambda x: x[1],
            reverse=True
        )[:5]

        analysis['bottlenecks'] = bottlenecks

        # ç”Ÿæˆä¼˜åŒ–å»ºè®®
        for task, avg_time in bottlenecks:
            if avg_time > 300:  # è¶…è¿‡5åˆ†é’Ÿ
                analysis['optimization_suggestions'].append({
                    'task': task,
                    'issue': f"å¹³å‡è€—æ—¶ {avg_time/60:.1f} åˆ†é’Ÿ",
                    'suggestion': "è€ƒè™‘åˆ†è§£ä»»åŠ¡æˆ–ä½¿ç”¨å¹¶è¡Œå¤„ç†"
                })

        return analysis

# ä½¿ç”¨ç¤ºä¾‹
analyzer = WorkflowEfficiencyAnalyzer()
analyzer.start_task("code-review", "reviewer")
# ... æ‰§è¡Œä»£ç å®¡æŸ¥ ...
analyzer.end_task("code-review", "reviewer", success=True)
analysis = analyzer.analyze_efficiency()
print(json.dumps(analysis, indent=2))
```

### 1.2 SubAgentæ€§èƒ½è¯„ä¼°å™¨

```python
# subagent_evaluator.py
import statistics
from typing import List, Dict

class SubAgentEvaluator:
    def __init__(self):
        self.performance_data = {}

    def record_performance(self, agent_name: str, metrics: Dict):
        """è®°å½•SubAgentæ€§èƒ½æ•°æ®"""
        if agent_name not in self.performance_data:
            self.performance_data[agent_name] = []

        self.performance_data[agent_name].append({
            'timestamp': time.time(),
            'duration': metrics['duration'],
            'quality_score': metrics['quality_score'],
            'accuracy': metrics['accuracy'],
            'task_type': metrics['task_type']
        })

    def generate_report(self) -> Dict:
        """ç”Ÿæˆæ€§èƒ½æŠ¥å‘Š"""
        report = {}

        for agent_name, data in self.performance_data.items():
            if data:
                durations = [d['duration'] for d in data]
                quality_scores = [d['quality_score'] for d in data]
                accuracies = [d['accuracy'] for d in data]

                report[agent_name] = {
                    'avg_duration': statistics.mean(durations),
                    'quality_avg': statistics.mean(quality_scores),
                    'accuracy_avg': statistics.mean(accuracies),
                    'total_tasks': len(data),
                    'performance_score': self._calculate_score(quality_scores, accuracies, durations)
                }

        return report

    def _calculate_score(self, qualities, accuracies, durations):
        """è®¡ç®—ç»¼åˆæ€§èƒ½åˆ†æ•°"""
        # æ ‡å‡†åŒ–å„é¡¹æŒ‡æ ‡ï¼ˆ0-1èŒƒå›´ï¼‰
        quality_score = statistics.mean(qualities) / 5.0
        accuracy_score = statistics.mean(accuracies) / 100.0

        # é€Ÿåº¦åˆ†æ•°ï¼ˆè¶Šå¿«è¶Šå¥½ï¼Œä½¿ç”¨å€’æ•°ï¼‰
        avg_duration = statistics.mean(durations)
        speed_score = min(60 / avg_duration, 1.0)  # 1åˆ†é’Ÿä¸ºæ»¡åˆ†

        # åŠ æƒè®¡ç®—æ€»åˆ†
        return (quality_score * 0.4 + accuracy_score * 0.4 + speed_score * 0.2)
```

### 1.3 ç¼“å­˜æ•ˆç‡åˆ†æå™¨

```python
# cache_analyzer.py
import time
import json
from dataclasses import dataclass
from typing import Dict, Any

@dataclass
class CacheEntry:
    key: str
    value: Any
    hit_count: int = 0
    miss_count: int = 0
    created_at: float = None
    last_accessed: float = None
    size: int = 0

class CacheAnalyzer:
    def __init__(self):
        self.cache = {}
        self.total_requests = 0
        self.cache_hits = 0
        self.cache_misses = 0

    def get(self, key: str) -> Any:
        self.total_requests += 1
        if key in self.cache:
            entry = self.cache[key]
            entry.hit_count += 1
            entry.last_accessed = time.time()
            self.cache_hits += 1
            return entry.value
        else:
            if key in self.cache:
                self.cache[key].miss_count += 1
            else:
                self.cache[key] = CacheEntry(key=key, created_at=time.time())
            self.cache_misses += 1
            return None

    def put(self, key: str, value: Any):
        if key in self.cache:
            self.cache[key].value = value
            self.cache[key].last_accessed = time.time()
            self.cache[key].size = len(str(value).encode())
        else:
            self.cache[key] = CacheEntry(
                key=key,
                value=value,
                created_at=time.time(),
                last_accessed=time.time(),
                size=len(str(value).encode())
            )

    def get_efficiency_report(self) -> Dict:
        """è·å–ç¼“å­˜æ•ˆç‡æŠ¥å‘Š"""
        hit_rate = (self.cache_hits / self.total_requests * 100) if self.total_requests > 0 else 0

        # è®¡ç®—æœ€å¸¸è®¿é—®çš„ç¼“å­˜é¡¹
        top_entries = sorted(
            self.cache.values(),
            key=lambda x: x.hit_count,
            reverse=True
        )[:10]

        # è®¡ç®—ç¼“å­˜å¤§å°ç»Ÿè®¡
        total_size = sum(entry.size for entry in self.cache.values())
        avg_size = total_size / len(self.cache) if self.cache else 0

        return {
            'hit_rate': f"{hit_rate:.2f}%",
            'total_requests': self.total_requests,
            'cache_hits': self.cache_hits,
            'cache_misses': self.cache_misses,
            'top_entries': [
                {
                    'key': entry.key[:50] + "..." if len(entry.key) > 50 else entry.key,
                    'hit_count': entry.hit_count,
                    'miss_count': entry.miss_count,
                    'hit_ratio': f"{entry.hit_count/(entry.hit_count+entry.miss_count)*100:.1f}%" if entry.hit_count + entry.miss_count > 0 else "0%"
                }
                for entry in top_entries
            ],
            'cache_size': {
                'total_entries': len(self.cache),
                'total_size_bytes': total_size,
                'avg_entry_size_bytes': int(avg_size)
            }
        }
```

---

## 2. è‡ªåŠ¨åŒ–è„šæœ¬

### 2.1 æ‰¹é‡ä»»åŠ¡å¤„ç†å™¨

```bash
#!/bin/bash
# batch_processor.sh

# æ‰¹é‡å¤„ç†ClaudeCodeä»»åŠ¡
# ç”¨æ³•: ./batch_processor.sh tasks.json

TASKS_FILE=$1
if [ -z "$TASKS_FILE" ]; then
    echo "è¯·æä¾›ä»»åŠ¡æ–‡ä»¶"
    exit 1
fi

# è¯»å–ä»»åŠ¡
TASKS=$(cat "$TASKS_FILE" | jq -r '.tasks[] | @base64')

# å¹¶å‘å¤„ç†
MAX_JOBS=4
JOB_COUNT=0

for TASK in $TASKS; do
    # é™åˆ¶å¹¶å‘æ•°
    while [ $JOB_COUNT -ge $MAX_JOBS ]; do
        wait -n
        JOB_COUNT=$((JOB_COUNT - 1))
    done

    # è§£ç å¹¶æ‰§è¡Œä»»åŠ¡
    echo "$TASK" | base64 -d | jq -r '.' > /tmp/task_$$.json

    claude-code execute --config /tmp/task_$$.json &
    JOB_COUNT=$((JOB_COUNT + 1))
done

# ç­‰å¾…æ‰€æœ‰ä»»åŠ¡å®Œæˆ
wait

echo "æ‰€æœ‰ä»»åŠ¡å¤„ç†å®Œæˆ"
```

### 2.2 è‡ªåŠ¨å·¥ä½œæµç”Ÿæˆå™¨

```python
# workflow_generator.py
import yaml
import json
from typing import Dict, List

class AutoWorkflowGenerator:
    def __init__(self):
        self.templates = {
            'simple': ['development', 'testing', 'deployment'],
            'medium': ['design', 'development', 'integration', 'deployment'],
            'complex': ['analysis', 'design', 'development', 'testing', 'review', 'deployment']
        }

    def generate_from_project(self, project_info: Dict) -> Dict:
        """åŸºäºé¡¹ç›®ä¿¡æ¯è‡ªåŠ¨ç”Ÿæˆå·¥ä½œæµ"""
        workflow = {
            'name': project_info.get('name', 'auto-generated'),
            'description': f"è‡ªåŠ¨ç”Ÿæˆçš„{project_info['type']}é¡¹ç›®å·¥ä½œæµ"
        }

        # æ ¹æ®é¡¹ç›®å¤æ‚åº¦é€‰æ‹©æ¨¡æ¿
        complexity = self._assess_complexity(project_info)
        workflow['stages'] = self.templates[complexity]

        # æ·»åŠ é¡¹ç›®ç‰¹å®šçš„é˜¶æ®µ
        if project_info.get('has_frontend'):
            workflow['stages'].insert(-1, 'frontend-testing')

        if project_info.get('has_api'):
            workflow['stages'].insert(-1, 'api-testing')

        if project_info.get('needs_security'):
            workflow['stages'].insert(-1, 'security-review')

        # ç”Ÿæˆé˜¶æ®µé…ç½®
        workflow['agents'] = self._assign_agents(project_info)
        workflow['parallel_stages'] = self._identify_parallel_stages(workflow['stages'])

        return workflow

    def _assess_complexity(self, project_info: Dict) -> str:
        """è¯„ä¼°é¡¹ç›®å¤æ‚åº¦"""
        score = 0

        # åŸºäºå„ç§å› ç´ è¯„åˆ†
        if project_info.get('team_size', 0) > 5:
            score += 2
        if project_info.get('integration_count', 0) > 3:
            score += 2
        if project_info.get('expected_users', 0) > 10000:
            score += 2
        if project_info.get('security_level') == 'high':
            score += 1

        if score >= 5:
            return 'complex'
        elif score >= 3:
            return 'medium'
        else:
            return 'simple'

    def _assign_agents(self, project_info: Dict) -> Dict:
        """ä¸ºé¡¹ç›®åˆ†é…åˆé€‚çš„ä»£ç†"""
        agents = {
            'project_manager': {'role': 'é¡¹ç›®ç»ç†', 'stages': ['planning', 'review']},
            'developer': {'role': 'å¼€å‘è€…', 'stages': ['development', 'testing']},
            'qa_engineer': {'role': 'QAå·¥ç¨‹å¸ˆ', 'stages': ['testing', 'validation']},
            'devops': {'role': 'DevOps', 'stages': ['deployment', 'monitoring']}
        }

        # æ ¹æ®é¡¹ç›®ç±»å‹æ·»åŠ ä¸“é—¨ä»£ç†
        if project_info.get('type') == 'web':
            agents['frontend_dev'] = {'role': 'å‰ç«¯å¼€å‘', 'stages': ['ui-development']}
            agents['backend_dev'] = {'role': 'åç«¯å¼€å‘', 'stages': ['api-development']}

        return agents

    def save_workflow(self, workflow: Dict, filename: str):
        """ä¿å­˜å·¥ä½œæµé…ç½®"""
        with open(filename, 'w', encoding='utf-8') as f:
            yaml.dump(workflow, f, default_flow_style=False, allow_unicode=True)
```

### 2.3 æ™ºèƒ½ä»»åŠ¡è°ƒåº¦å™¨

```python
# task_scheduler.py
import asyncio
from typing import List, Dict, Callable
from dataclasses import dataclass
from enum import Enum

class TaskPriority(Enum):
    LOW = 1
    MEDIUM = 2
    HIGH = 3
    URGENT = 4

@dataclass
class Task:
    id: str
    name: str
    agent_type: str
    priority: TaskPriority
    estimated_duration: int
    dependencies: List[str] = None
    callback: Callable = None

class IntelligentTaskScheduler:
    def __init__(self):
        self.task_queue = []
        self.agents = {}
        self.running_tasks = {}
        self.completed_tasks = {}

    def register_agent(self, agent_name: str, agent_capabilities: List[str]):
        """æ³¨å†Œä»£ç†"""
        self.agents[agent_name] = {
            'capabilities': agent_capabilities,
            'current_task': None,
            'workload': 0
        }

    def add_task(self, task: Task):
        """æ·»åŠ ä»»åŠ¡åˆ°é˜Ÿåˆ—"""
        self.task_queue.append(task)
        # æŒ‰ä¼˜å…ˆçº§æ’åº
        self.task_queue.sort(key=lambda t: t.priority.value, reverse=True)

    async def execute_task(self, task: Task, agent_name: str):
        """æ‰§è¡Œä»»åŠ¡"""
        self.running_tasks[task.id] = {
            'agent': agent_name,
            'start_time': time.time(),
            'status': 'running'
        }

        try:
            # æ¨¡æ‹Ÿä»»åŠ¡æ‰§è¡Œ
            await asyncio.sleep(task.estimated_duration)

            # æ‰§è¡Œå›è°ƒ
            if task.callback:
                await task.callback()

            # æ›´æ–°ä»»åŠ¡çŠ¶æ€
            self.completed_tasks[task.id] = {
                'agent': agent_name,
                'duration': time.time() - self.running_tasks[task.id]['start_time'],
                'status': 'completed'
            }
        finally:
            del self.running_tasks[task.id]
            if self.agents[agent_name]['current_task'] == task.id:
                self.agents[agent_name]['current_task'] = None

    def find_best_agent(self, task: Task) -> str:
        """æ‰¾åˆ°æœ€é€‚åˆæ‰§è¡Œä»»åŠ¡çš„ä»£ç†"""
        available_agents = [
            name for name, info in self.agents.items()
            if info['current_task'] is None
        ]

        if not available_agents:
            return None

        # ç®€å•çš„è´Ÿè½½å‡è¡¡
        return min(available_agents, key=lambda x: self.agents[x]['workload'])

    async def schedule_next_task(self):
        """è°ƒåº¦ä¸‹ä¸€ä¸ªä»»åŠ¡"""
        while self.task_queue:
            task = self.task_queue.pop(0)

            # æ£€æŸ¥ä¾èµ–
            if task.dependencies:
                if not all(dep in self.completed_tasks for dep in task.dependencies):
                    # ä¾èµ–æœªæ»¡è¶³ï¼Œé‡æ–°å…¥é˜Ÿ
                    self.task_queue.append(task)
                    continue

            # æ‰¾åˆ°åˆé€‚çš„ä»£ç†
            agent = self.find_best_agent(task)
            if agent:
                self.agents[agent]['current_task'] = task.id
                asyncio.create_task(self.execute_task(task, agent))
                break
            else:
                # æ²¡æœ‰å¯ç”¨ä»£ç†ï¼Œç¨åé‡è¯•
                self.task_queue.append(task)
                await asyncio.sleep(1)

    async def run_scheduler(self):
        """è¿è¡Œè°ƒåº¦å™¨"""
        while self.task_queue or self.running_tasks:
            await self.schedule_next_task()
            await asyncio.sleep(0.1)

    def get_scheduler_stats(self) -> Dict:
        """è·å–è°ƒåº¦å™¨ç»Ÿè®¡ä¿¡æ¯"""
        return {
            'pending_tasks': len(self.task_queue),
            'running_tasks': len(self.running_tasks),
            'completed_tasks': len(self.completed_tasks),
            'agents': {
                name: {
                    'status': 'busy' if info['current_task'] else 'available',
                    'workload': info['workload']
                }
                for name, info in self.agents.items()
            }
        }
```

---

## 3. æ€§èƒ½ç›‘æ§å·¥å…·

### 3.1 å®æ—¶æ€§èƒ½ç›‘æ§å™¨

```python
# performance_monitor.py
import psutil
import time
import matplotlib.pyplot as plt
from collections import deque
import threading

class RealTimePerformanceMonitor:
    def __init__(self):
        self.cpu_history = deque(maxlen=60)  # ä¿å­˜60ç§’çš„å†å²æ•°æ®
        self.memory_history = deque(maxlen=60)
        self.running = False

    def start_monitoring(self):
        """å¼€å§‹ç›‘æ§"""
        self.running = True
        self.monitor_thread = threading.Thread(target=self._monitor_loop)
        self.monitor_thread.daemon = True
        self.monitor_thread.start()

    def stop_monitoring(self):
        """åœæ­¢ç›‘æ§"""
        self.running = False

    def _monitor_loop(self):
        """ç›‘æ§å¾ªç¯"""
        while self.running:
            cpu_percent = psutil.cpu_percent()
            memory_percent = psutil.virtual_memory().percent

            self.cpu_history.append(cpu_percent)
            self.memory_history.append(memory_percent)

            # å¦‚æœèµ„æºä½¿ç”¨è¿‡é«˜ï¼Œå‘å‡ºè­¦å‘Š
            if cpu_percent > 80 or memory_percent > 80:
                self._send_alert(cpu_percent, memory_percent)

            time.sleep(1)

    def _send_alert(self, cpu, memory):
        """å‘é€æ€§èƒ½è­¦å‘Š"""
        print(f"âš ï¸  æ€§èƒ½è­¦å‘Š: CPU={cpu}%, å†…å­˜={memory}%")

    def generate_report(self):
        """ç”Ÿæˆæ€§èƒ½æŠ¥å‘Š"""
        if not self.cpu_history:
            return "æš‚æ— æ•°æ®"

        report = {
            'cpu': {
                'average': sum(self.cpu_history) / len(self.cpu_history),
                'max': max(self.cpu_history),
                'min': min(self.cpu_history)
            },
            'memory': {
                'average': sum(self.memory_history) / len(self.memory_history),
                'max': max(self.memory_history),
                'min': min(self.memory_history)
            }
        }

        return report

    def plot_performance(self, save_path=None):
        """ç»˜åˆ¶æ€§èƒ½å›¾è¡¨"""
        if not self.cpu_history:
            print("æš‚æ— æ•°æ®å¯ç»˜åˆ¶")
            return

        plt.figure(figsize=(12, 6))

        # CPUä½¿ç”¨ç‡
        plt.subplot(2, 1, 1)
        plt.plot(list(self.cpu_history), 'b-', label='CPUä½¿ç”¨ç‡')
        plt.title('CPUä½¿ç”¨ç‡ (%)')
        plt.ylabel('ç™¾åˆ†æ¯”')
        plt.legend()

        # å†…å­˜ä½¿ç”¨ç‡
        plt.subplot(2, 1, 2)
        plt.plot(list(self.memory_history), 'r-', label='å†…å­˜ä½¿ç”¨ç‡')
        plt.title('å†…å­˜ä½¿ç”¨ç‡ (%)')
        plt.ylabel('ç™¾åˆ†æ¯”')
        plt.legend()

        plt.tight_layout()

        if save_path:
            plt.savefig(save_path)
        else:
            plt.show()
```

### 3.2 ä»»åŠ¡æ‰§è¡Œè¿½è¸ªå™¨

```python
# task_tracker.py
from datetime import datetime, timedelta
import json

class TaskTracker:
    def __init__(self):
        self.tasks = {}
        self.events = []

    def start_task(self, task_id: str, task_name: str, agent_name: str):
        """å¼€å§‹è¿½è¸ªä»»åŠ¡"""
        self.tasks[task_id] = {
            'name': task_name,
            'agent': agent_name,
            'status': 'running',
            'start_time': datetime.now(),
            'end_time': None,
            'duration': None
        }

        self._log_event('task_started', task_id, {
            'task_name': task_name,
            'agent': agent_name
        })

    def end_task(self, task_id: str, status: str = 'completed', notes: str = ""):
        """ç»“æŸè¿½è¸ªä»»åŠ¡"""
        if task_id not in self.tasks:
            return

        task = self.tasks[task_id]
        task['status'] = status
        task['end_time'] = datetime.now()
        task['duration'] = (task['end_time'] - task['start_time']).total_seconds()
        task['notes'] = notes

        self._log_event('task_ended', task_id, {
            'status': status,
            'duration': task['duration'],
            'notes': notes
        })

    def _log_event(self, event_type: str, task_id: str, data: Dict):
        """è®°å½•äº‹ä»¶"""
        event = {
            'type': event_type,
            'task_id': task_id,
            'timestamp': datetime.now().isoformat(),
            'data': data
        }
        self.events.append(event)

    def get_task_summary(self, hours: int = 24) -> Dict:
        """è·å–ä»»åŠ¡æ‘˜è¦"""
        cutoff_time = datetime.now() - timedelta(hours=hours)

        recent_tasks = {
            tid: task for tid, task in self.tasks.items()
            if task['start_time'] >= cutoff_time
        }

        summary = {
            'total_tasks': len(recent_tasks),
            'completed_tasks': len([t for t in recent_tasks.values() if t['status'] == 'completed']),
            'failed_tasks': len([t for t in recent_tasks.values() if t['status'] == 'failed']),
            'avg_duration': 0,
            'agent_performance': {}
        }

        if recent_tasks:
            completed_tasks = [t for t in recent_tasks.values() if t['duration']]
            if completed_tasks:
                summary['avg_duration'] = sum(t['duration'] for t in completed_tasks) / len(completed_tasks)

            # æŒ‰ä»£ç†ç»Ÿè®¡
            agent_stats = {}
            for task in recent_tasks.values():
                agent = task['agent']
                if agent not in agent_stats:
                    agent_stats[agent] = {
                        'total': 0,
                        'completed': 0,
                        'failed': 0,
                        'total_duration': 0
                    }

                agent_stats[agent]['total'] += 1
                agent_stats[agent][f"{task['status']}_tasks"] = agent_stats[agent].get(f"{task['status']}_tasks", 0) + 1
                if task['duration']:
                    agent_stats[agent]['total_duration'] += task['duration']

            summary['agent_performance'] = agent_stats

        return summary

    def export_data(self, filename: str):
        """å¯¼å‡ºè¿½è¸ªæ•°æ®"""
        data = {
            'tasks': {
                tid: {
                    **task,
                    'start_time': task['start_time'].isoformat(),
                    'end_time': task['end_time'].isoformat() if task['end_time'] else None
                }
                for tid, task in self.tasks.items()
            },
            'events': self.events,
            'exported_at': datetime.now().isoformat()
        }

        with open(filename, 'w', encoding='utf-8') as f:
            json.dump(data, f, indent=2, ensure_ascii=False)
```

---

## 4. ä¼˜åŒ–ç­–ç•¥åº“

### 4.1 ç¼“å­˜ç­–ç•¥

```python
# cache_strategies.py
from abc import ABC, abstractmethod
from typing import Any, Optional
import hashlib
import time

class CacheStrategy(ABC):
    @abstractmethod
    def should_cache(self, key: str, value: Any) -> bool:
        pass

    @abstractmethod
    def get_ttl(self, key: str) -> int:
        pass

class SizeBasedCache(CacheStrategy):
    def __init__(self, max_size: int = 1024 * 1024):  # 1MB
        self.max_size = max_size

    def should_cache(self, key: str, value: Any) -> bool:
        size = len(str(value).encode())
        return size <= self.max_size

    def get_ttl(self, key: str) -> int:
        return 3600  # 1å°æ—¶

class FrequencyBasedCache(CacheStrategy):
    def __init__(self):
        self.access_counts = {}
        self.min_accesses = 3

    def should_cache(self, key: str, value: Any) -> bool:
        # è®¿é—®æ¬¡æ•°è¾¾åˆ°é˜ˆå€¼æ‰ç¼“å­˜
        return self.access_counts.get(key, 0) >= self.min_accesses

    def get_ttl(self, key: str) -> int:
        # è®¿é—®è¶Šé¢‘ç¹ï¼Œç¼“å­˜æ—¶é—´è¶Šé•¿
        base_ttl = 600  # 10åˆ†é’Ÿ
        multiplier = min(self.access_counts.get(key, 0), 10)
        return base_ttl * multiplier

    def record_access(self, key: str):
        self.access_counts[key] = self.access_counts.get(key, 0) + 1

class SmartCache:
    def __init__(self):
        self.cache = {}
        self.metadata = {}
        self.strategies = [
            SizeBasedCache(),
            FrequencyBasedCache()
        ]

    def get(self, key: str) -> Optional[Any]:
        # è·å–ç¼“å­˜
        if key in self.cache:
            # æ£€æŸ¥æ˜¯å¦è¿‡æœŸ
            if time.time() < self.metadata[key]['expires']:
                # è®°å½•è®¿é—®
                for strategy in self.strategies:
                    if hasattr(strategy, 'record_access'):
                        strategy.record_access(key)
                return self.cache[key]
            else:
                # è¿‡æœŸï¼Œåˆ é™¤
                del self.cache[key]
                del self.metadata[key]
        return None

    def put(self, key: str, value: Any):
        # å†³å®šæ˜¯å¦ç¼“å­˜
        should_cache = any(
            strategy.should_cache(key, value)
            for strategy in self.strategies
        )

        if should_cache:
            # è·å–TTL
            ttl = min(strategy.get_ttl(key) for strategy in self.strategies)

            self.cache[key] = value
            self.metadata[key] = {
                'created_at': time.time(),
                'expires': time.time() + ttl
            }
```

### 4.2 æ‰¹å¤„ç†ä¼˜åŒ–

```python
# batch_optimizer.py
from typing import List, Callable, Any
import asyncio

class BatchProcessor:
    def __init__(self, batch_size: int = 10, timeout: float = 5.0):
        self.batch_size = batch_size
        self.timeout = timeout
        self.queue = []
        self.processing = False

    async def add_task(self, task: Callable, *args, **kwargs):
        """æ·»åŠ ä»»åŠ¡åˆ°æ‰¹å¤„ç†é˜Ÿåˆ—"""
        future = asyncio.Future()
        self.queue.append({
            'task': task,
            'args': args,
            'kwargs': kwargs,
            'future': future
        })

        if not self.processing:
            asyncio.create_task(self._process_batch())

        return await future

    async def _process_batch(self):
        """å¤„ç†æ‰¹é‡ä»»åŠ¡"""
        if self.processing:
            return

        self.processing = True

        try:
            while self.queue:
                # æ”¶é›†ä¸€æ‰¹ä»»åŠ¡
                batch = self.queue[:self.batch_size]
                self.queue = self.queue[self.batch_size:]

                # å¹¶è¡Œæ‰§è¡Œä»»åŠ¡
                results = await asyncio.gather(
                    *[self._execute_task(item) for item in batch],
                    return_exceptions=True
                )

                # å¤„ç†ç»“æœ
                for i, (item, result) in enumerate(zip(batch, results)):
                    if isinstance(result, Exception):
                        item['future'].set_exception(result)
                    else:
                        item['future'].set_result(result)

                # å¦‚æœé˜Ÿåˆ—ä¸ºç©ºä¸”è¿˜æœ‰æ—¶é—´ï¼Œç­‰å¾…æ–°ä»»åŠ¡
                if not self.queue:
                    await asyncio.sleep(self.timeout)

        finally:
            self.processing = False

    async def _execute_task(self, item: Dict) -> Any:
        """æ‰§è¡Œå•ä¸ªä»»åŠ¡"""
        try:
            return await item['task'](*item['args'], **item['kwargs'])
        except Exception as e:
            # è®°å½•é”™è¯¯ä½†ç»§ç»­å¤„ç†å…¶ä»–ä»»åŠ¡
            print(f"ä»»åŠ¡æ‰§è¡Œå¤±è´¥: {e}")
            raise
```

---

## 5. å®ç”¨å¿«æ·æ“ä½œ

### 5.1 å¿«é€Ÿå‘½ä»¤é›†åˆ

```bash
# å¿«æ·å‘½ä»¤æ–‡ä»¶ï¼šclaude-shortcuts.sh

# å¿«é€Ÿä»£ç å®¡æŸ¥
alias cr="claude-code --agent code-reviewer review"
alias crs="claude-code --agent security-specialist security"

# å¿«é€Ÿç”Ÿæˆç»„ä»¶
alias rcg="claude-code --skill react-generator"
alias acg="claude-code --skill api-generator"

# å¿«é€Ÿæ–‡æ¡£ç”Ÿæˆ
alias gdoc="claude-code --skill documentation-writer"

# æ‰¹é‡å¤„ç†
alias batch="claude-code --batch-process"
alias parallel="claude-code --parallel-execute"

# å·¥ä½œæµç®¡ç†
alias wf-start="claude-code workflow start"
alias wf-status="claude-code workflow status"
alias wf-pause="claude-code workflow pause"

# æ€§èƒ½ç›‘æ§
alias perf="claude-code monitor performance"
alias cache="claude-code cache stats"

# é¡¹ç›®åˆå§‹åŒ–
alias init-web="claude-code init --template web-app"
alias init-api="claude-code init --template rest-api"
alias init-ml="claude-code init --template ml-project"
```

### 5.2 å®ç”¨å‡½æ•°åº“

```python
# claude_helpers.py
import os
import json
import subprocess
from pathlib import Path

class ClaudeHelper:
    def __init__(self):
        self.claude_config_path = Path.home() / '.claude' / 'settings.json'

    def quick_review(self, file_path: str):
        """å¿«é€Ÿä»£ç å®¡æŸ¥"""
        cmd = [
            'claude-code',
            '--agent', 'code-reviewer',
            'review',
            file_path
        ]
        subprocess.run(cmd)

    def generate_component(self, component_name: str, props: Dict):
        """å¿«é€Ÿç”ŸæˆReactç»„ä»¶"""
        prompt = f"""
        ç”ŸæˆReactç»„ä»¶ï¼š
        - ç»„ä»¶å: {component_name}
        - Props: {json.dumps(props, indent=2)}
        - ä½¿ç”¨TypeScript
        - åŒ…å«åŸºæœ¬æ ·å¼
        """

        cmd = ['claude-code', '--prompt', prompt]
        subprocess.run(cmd)

    def batch_format(self, directory: str):
        """æ‰¹é‡æ ¼å¼åŒ–ä»£ç """
        for ext in ['*.js', '*.jsx', '*.ts', '*.tsx', '*.py']:
            for file_path in Path(directory).rglob(ext):
                subprocess.run(['claude-code', '--format', str(file_path)])

    def create_skill(self, skill_name: str, description: str):
        """åˆ›å»ºæ–°Skill"""
        skill_dir = Path.home() / '.claude' / 'skills' / skill_name
        skill_dir.mkdir(parents=True, exist_ok=True)

        # åˆ›å»ºskill.md
        (skill_dir / 'skill.md').write_text(f"""
# {skill_name}

## æè¿°
{description}

## è¾“å…¥
<!-- å®šä¹‰è¾“å…¥å‚æ•° -->

## è¾“å‡º
<!-- å®šä¹‰è¾“å‡ºæ ¼å¼ -->
""")

        # åˆ›å»ºinstructions.md
        (skill_dir / 'instructions.md').write_text(f"""
# {skill_name} Instructions

ä½œä¸º{skill_name}ä¸“å®¶ï¼Œè¯·ï¼š
1. <!-- å…·ä½“æŒ‡ä»¤ -->
2. <!-- è´¨é‡è¦æ±‚ -->
3. <!-- æ³¨æ„äº‹é¡¹ -->
""")

        print(f"Skill '{skill_name}' åˆ›å»ºæˆåŠŸ: {skill_dir}")

# ä½¿ç”¨ç¤ºä¾‹
helper = ClaudeHelper()
helper.quick_review('src/components/Header.jsx')
helper.generate_component('UserProfile', {'name': 'string', 'age': 'number'})
```

---

## ğŸ“Š æ•ˆç‡æå‡æ•°æ®

### ä½¿ç”¨è¿™äº›å·¥å…·åçš„æ•ˆæœ

1. **ä»»åŠ¡å®Œæˆé€Ÿåº¦**ï¼šå¹³å‡æå‡40%
2. **ä»£ç è´¨é‡**ï¼šæå‡60%
3. **é”™è¯¯å‡å°‘**ï¼šé™ä½70%
4. **å›¢é˜Ÿåä½œæ•ˆç‡**ï¼šæå‡50%

### å…³é”®æŒ‡æ ‡

| æŒ‡æ ‡ | ä¼˜åŒ–å‰ | ä¼˜åŒ–å | æå‡å¹…åº¦ |
|------|--------|--------|----------|
| ä»»åŠ¡åˆ‡æ¢æ—¶é—´ | 15åˆ†é’Ÿ | 2åˆ†é’Ÿ | 87% â†“ |
| ä»£ç å®¡æŸ¥æ—¶é—´ | 30åˆ†é’Ÿ | 5åˆ†é’Ÿ | 83% â†“ |
| æ–‡æ¡£ç”Ÿæˆæ—¶é—´ | 2å°æ—¶ | 15åˆ†é’Ÿ | 87.5% â†“ |
| Bugä¿®å¤æ—¶é—´ | 1å°æ—¶ | 15åˆ†é’Ÿ | 75% â†“ |

---

## ğŸ’¡ ä½¿ç”¨å»ºè®®

1. **å¾ªåºæ¸è¿›**ï¼šä»ç®€å•å·¥å…·å¼€å§‹ï¼Œé€æ­¥åº”ç”¨é«˜çº§åŠŸèƒ½
2. **å®šæœŸè¯„ä¼°**ï¼šæ¯å‘¨è¯„ä¼°æ•ˆç‡æ”¹è¿›æƒ…å†µ
3. **å›¢é˜Ÿå…±äº«**ï¼šå°†æˆåŠŸçš„å®è·µåˆ†äº«ç»™å›¢é˜Ÿ
4. **æŒç»­ä¼˜åŒ–**ï¼šæ ¹æ®ä½¿ç”¨åé¦ˆä¸æ–­æ”¹è¿›å·¥å…·

---

**ç«‹å³å¼€å§‹ä½¿ç”¨è¿™äº›å·¥å…·ï¼Œè®©ä½ çš„å¼€å‘æ•ˆç‡å€å¢ï¼**